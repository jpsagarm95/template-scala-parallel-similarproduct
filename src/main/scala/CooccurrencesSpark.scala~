package org.template.similarproduct

import io.prediction.controller.P2LAlgorithm
import io.prediction.controller.Params


import org.apache.spark.SparkContext
import org.apache.spark.SparkContext._
import org.apache.spark.mllib.recommendation.ALS
import org.apache.spark.mllib.recommendation.{Rating => MLlibRating}

//@sagar_start
import collection.immutable.ListMap
import org.apache.mahout.math.DenseVector
import org.apache.mahout.math.drm._
import scala.collection.Seq
import scala.collection.GenSeq
import scala.collection.mutable.ArrayBuffer
import com.google.common.collect.BiMap
import com.google.common.collect.HashBiMap
import scala.util.control._
import org.apache.mahout.math.drm.CheckpointedDrm
import org.apache.mahout.sparkbindings
import org.apache.mahout.sparkbindings.indexeddataset.IndexedDatasetSpark
import org.apache.mahout.math.indexeddataset.IndexedDataset
import org.apache.mahout.sparkbindings.drm.CheckpointedDrmSpark
import org.apache.mahout.math.Vector
import org.apache.mahout.math.VectorWritable
import org.apache.spark.mllib.linalg.Vectors
import collection.JavaConverters._
//@sagar_stop

//@sagar_start
import com.google.common.collect.BiMap
import org.apache.mahout.math.cf.SimilarityAnalysis
import org.apache.mahout.math.drm.CheckpointedDrm
import org.apache.mahout.math.indexeddataset.{IndexedDataset, Schema}
import org.apache.mahout.sparkbindings.indexeddataset.IndexedDatasetSpark
import org.apache.mahout.sparkbindings.drm.CheckpointedDrmSpark
//@sagar_stop

import grizzled.slf4j.Logger

import scala.collection.mutable.PriorityQueue
//@sagar_start
case class COSAlgorithmParams(
  randomSeed: Int = 0xdeadbeef,
  maxInterestingItemsPerThing: Int = 50,
  maxNumInteractions: Int = 500
  ) extends Params

class COSModel(
  //val indicatorMatrix : List[IndexedDataset],
 // val itemStringtoInt : BiMap[String, Int]
) extends Serializable {
//@sagar_stop
//  @transient lazy val itemIntStringMap = itemStringtoInt.inverse

/*  override def toString = {
    s" productFeatures: [${productFeatures.size}]" +
    s"(${productFeatures.take(2).toList}...)" +
    s" itemStringIntMap: [${itemStringIntMap.size}]" +
    s"(${itemStringIntMap.take(2).toString}...)]" +
    s" items: [${items.size}]" +
    s"(${items.take(2).toString}...)]"
  }*/
}

/**
  * Use ALS to build item x feature matrix
  */
class COSAlgorithm(val ap: COSAlgorithmParams)
  extends P2LAlgorithm[PreparedData, COSModel, Query, PredictedResult] {

  @transient lazy val logger = Logger[this.type]

  def train(sc: SparkContext, data: PreparedData): COSModel = {
    require(!data.viewEvents.take(1).isEmpty,
      s"viewEvents in PreparedData cannot be empty." +
      " Please check if DataSource generates TrainingData" +
      " and Preprator generates PreparedData correctly.")
    require(!data.users.take(1).isEmpty,
      s"users in PreparedData cannot be empty." +
      " Please check if DataSource generates TrainingData" +
      " and Preprator generates PreparedData correctly.")
    require(!data.items.take(1).isEmpty,
      s"items in PreparedData cannot be empty." +
      " Please check if DataSource generates TrainingData" +
      " and Preprator generates PreparedData correctly.")

    val userItemMatrixArray: Array[IndexedDataset] = new Array[IndexedDataset](1)
    userItemMatrixArray(0) = data.userItemMatrix

/*    val indicatorMatrix = SimilarityAnalysis.cooccurrencesIDSs( 
    		userItemMatrixArray,
    		ap.randomSeed,
    		ap.maxInterestingItemsPerThing,
    		ap.maxNumInteractions)
*/
  //  println(indicatorMatrix(0))
    new COSModel(
    //  indicatorMatrix = indicatorMatrix,
    //  itemStringtoInt = itemsG
    )
  }

  def predict(model: COSModel, query: Query): PredictedResult = {/*

    val productFeatures = model.productFeatures

    // convert items to Int index
    val queryList: Set[Int] = query.items.map(model.itemStringIntMap.get(_))
      .flatten.toSet

    val queryFeatures: Vector[Array[Double]] = queryList.toVector
      // productFeatures may not contain the requested item
      .map { item => productFeatures.get(item) }
      .flatten

    val whiteList: Option[Set[Int]] = query.whiteList.map( set =>
      set.map(model.itemStringIntMap.get(_)).flatten
    )
    val blackList: Option[Set[Int]] = query.blackList.map ( set =>
      set.map(model.itemStringIntMap.get(_)).flatten
    )

    val ord = Ordering.by[(Int, Double), Double](_._2).reverse

    val indexScores: Array[(Int, Double)] = if (queryFeatures.isEmpty) {
      logger.info(s"No productFeatures vector for query items ${query.items}.")
      Array[(Int, Double)]()
    } else {
      productFeatures.par // convert to parallel collection
        .mapValues { f =>
          queryFeatures.map{ qf =>
            cosine(qf, f)
          }.reduce(_ + _)
        }
        .filter(_._2 > 0) // keep items with score > 0
        .seq // convert back to sequential collection
        .toArray
    }

    val filteredScore = indexScores.view.filter { case (i, v) =>
      isCandidateItem(
        i = i,
        items = model.items,
        categories = query.categories,
        queryList = queryList,
        whiteList = whiteList,
        blackList = blackList
      )
    }

    val topScores = getTopN(filteredScore, query.num)(ord).toArray

    val itemScores = topScores.map { case (i, s) =>
      new ItemScore(
        item = model.itemIntStringMap(i),
        score = s
      )
    }
*/
    new PredictedResult(null)
  }

  private
  def getTopN[T](s: Seq[T], n: Int)(implicit ord: Ordering[T]): Seq[T] = {

    val q = PriorityQueue()

    for (x <- s) {
      if (q.size < n)
        q.enqueue(x)
      else {
        // q is full
        if (ord.compare(x, q.head) < 0) {
          q.dequeue()
          q.enqueue(x)
        }
      }
    }

    q.dequeueAll.toSeq.reverse
  }

  private
  def cosine(v1: Array[Double], v2: Array[Double]): Double = {
    val size = v1.size
    var i = 0
    var n1: Double = 0
    var n2: Double = 0
    var d: Double = 0
    while (i < size) {
      n1 += v1(i) * v1(i)
      n2 += v2(i) * v2(i)
      d += v1(i) * v2(i)
      i += 1
    }
    val n1n2 = (math.sqrt(n1) * math.sqrt(n2))
    if (n1n2 == 0) 0 else (d / n1n2)
  }

  private
  def isCandidateItem(
    i: Int,
    items: Map[Int, Item],
    categories: Option[Set[String]],
    queryList: Set[Int],
    whiteList: Option[Set[Int]],
    blackList: Option[Set[Int]]
  ): Boolean = {
    whiteList.map(_.contains(i)).getOrElse(true) &&
    blackList.map(!_.contains(i)).getOrElse(true) &&
    // discard items in query as well
    (!queryList.contains(i)) &&
    // filter categories
    categories.map { cat =>
      items(i).categories.map { itemCat =>
        // keep this item if has ovelap categories with the query
        !(itemCat.toSet.intersect(cat).isEmpty)
      }.getOrElse(false) // discard this item if it has no categories
    }.getOrElse(true)
  }
}
